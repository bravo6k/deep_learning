{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_data import *\n",
    "from dnn_implementation import *\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading test data\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_data()\n",
    "x_train = x_train[:,:500]\n",
    "y_train = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = x_train.shape[1]\n",
    "n_test = x_test.shape[1]\n",
    "num_px = int(np.sqrt(x_train.shape[0]))\n",
    "n_class = len(np.unique(y_train))\n",
    "# one hot y\n",
    "y_train_oh = np.zeros((n_class, n_train))\n",
    "y_train_oh[y_train,np.arange(n_train)] = 1\n",
    "y_test_oh = np.zeros((n_class, n_test))\n",
    "y_test_oh[y_test,np.arange(n_test)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_number = 10\n",
    "plt.imshow(x_train[:,sample_number].reshape(28,28), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "print(\"Image Label: \", y_train[sample_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 500\n",
      "Number of testing examples: 10000\n",
      "Each image is of size: (28, 28)\n",
      "x_train shape: (784, 500)\n",
      "y_train one hot shape: (10, 500)\n",
      "x_test shape: (784, 10000)\n",
      "y_test one hot shape: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "print (\"Number of training examples: \" + str(n_train))\n",
    "print (\"Number of testing examples: \" + str(n_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \")\")\n",
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"y_train one hot shape: \" + str(y_train_oh.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test one hot shape: \" + str(y_test_oh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 5, 3, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = [ReLU,ReLU,Softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Neural_Network(layer_list=layers_dims,activation_function=activation_function,lambd=0,\n",
    "                         keep_prob=1,mini_batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3983, 1)\n",
      "\u001b[93mThere is a mistake in the backward propagation! difference = 0.6947882318872467\u001b[0m\n",
      "(3983, 1)\n",
      "\u001b[93mThere is a mistake in the backward propagation! difference = 0.6703095289387614\u001b[0m\n",
      "(3983, 1)\n",
      "\u001b[93mThere is a mistake in the backward propagation! difference = 0.6778314186471414\u001b[0m\n",
      "Cost after iteration 0: 2.302669\n",
      "(3983, 1)\n",
      "\u001b[93mThere is a mistake in the backward propagation! difference = 0.6829389441590892\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0c649fe7788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads_check\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/deep_learning/Tryout/dnn_implementation.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, epoch, print_cost, grads_check)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;31m# Check gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgrads_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fun_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;31m# Print the cost every 50 training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/deep_learning/Tryout/dnn_implementation.py\u001b[0m in \u001b[0;36mgradient_check\u001b[0;34m(parameters, gradients, X, Y, act_fun_list, keep_prob, lambd, epsilon)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mthetaminus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mthetaminus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetaminus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_to_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetaminus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_fun_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fun_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mJ_minus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/deep_learning/Tryout/dnn_implementation.py\u001b[0m in \u001b[0;36mvector_to_dictionary\u001b[0;34m(old_p, _, vec)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0;32m--> 637\u001b[0;31m                 invert=invert).reshape(element.shape)\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Check if one of the arrays may contain arbitrary objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mcontains_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;31m# This code is run when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network.train(X=x_train,Y=y_train_oh,epoch=8,print_cost=True,grads_check =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(network.costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per 50s)')\n",
    "plt.title(\"Learning rate =\" + str(network.learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = {'A1':[2,3,4],'W1':[2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in aa.keys() if \"A\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
